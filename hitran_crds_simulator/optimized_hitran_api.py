"""
ìµœì í™”ëœ HITRAN API (ìºì‹± + ë³‘ë ¬ ì²˜ë¦¬)
"""

from astroquery import hitran
import os
import pandas as pd
import astropy.units as u
import concurrent.futures
import pickle
import hashlib
from datetime import datetime
import time

class HitranCache:
    def __init__(self, cache_dir="cache/hitran_cache"):
        self.cache_dir = cache_dir
        
        # ìºì‹œ í´ë” ìƒì„±
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
        
        # ìºì‹œ ë©”íƒ€ë°ì´í„° íŒŒì¼
        self.metadata_file = os.path.join(cache_dir, "cache_metadata.json")
        self.load_metadata()
    
    def load_metadata(self):
        """ìºì‹œ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if os.path.exists(self.metadata_file):
            try:
                self.metadata = pd.read_json(self.metadata_file)
            except:
                self.metadata = pd.DataFrame(columns=['cache_key', 'file_path', 'created_time', 'access_count', 'file_size'])
        else:
            self.metadata = pd.DataFrame(columns=['cache_key', 'file_path', 'created_time', 'access_count', 'file_size'])
    
    def save_metadata(self):
        """ìºì‹œ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        self.metadata.to_json(self.metadata_file, orient='records', date_format='iso')
    
    def generate_cache_key(self, molecule, wavelength_min, wavelength_max):
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_string = f"{molecule}_{wavelength_min}_{wavelength_max}"
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def get_cache_path(self, cache_key):
        """ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        return os.path.join(self.cache_dir, f"{cache_key}.pkl")
    
    def is_cached(self, molecule, wavelength_min, wavelength_max):
        """ìºì‹œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        cache_key = self.generate_cache_key(molecule, wavelength_min, wavelength_max)
        cache_path = self.get_cache_path(cache_key)
        return os.path.exists(cache_path)
    
    def save_to_cache(self, molecule, wavelength_min, wavelength_max, data):
        """ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥"""
        cache_key = self.generate_cache_key(molecule, wavelength_min, wavelength_max)
        cache_path = self.get_cache_path(cache_key)
        
        try:
            # ë°ì´í„° ì €ì¥
            with open(cache_path, 'wb') as f:
                pickle.dump(data, f)
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            file_size = os.path.getsize(cache_path)
            new_entry = pd.DataFrame({
                'cache_key': [cache_key],
                'file_path': [cache_path],
                'created_time': [datetime.now().isoformat()],
                'access_count': [1],
                'file_size': [file_size],
                'molecule': [molecule],
                'wavelength_min': [wavelength_min],
                'wavelength_max': [wavelength_max]
            })
            
            # ê¸°ì¡´ í•­ëª© ì œê±° í›„ ì¶”ê°€
            self.metadata = self.metadata[self.metadata['cache_key'] != cache_key]
            self.metadata = pd.concat([self.metadata, new_entry], ignore_index=True)
            self.save_metadata()
            
            return True
        except Exception as e:
            print(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def load_from_cache(self, molecule, wavelength_min, wavelength_max):
        """ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ"""
        cache_key = self.generate_cache_key(molecule, wavelength_min, wavelength_max)
        cache_path = self.get_cache_path(cache_key)
        
        try:
            with open(cache_path, 'rb') as f:
                data = pickle.load(f)
            
            # ì ‘ê·¼ íšŸìˆ˜ ì¦ê°€
            mask = self.metadata['cache_key'] == cache_key
            if mask.any():
                self.metadata.loc[mask, 'access_count'] += 1
                self.save_metadata()
            
            return data
        except Exception as e:
            print(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_cache_stats(self):
        """ìºì‹œ í†µê³„ ì •ë³´"""
        if len(self.metadata) == 0:
            return {
                'total_files': 0,
                'total_size_mb': 0,
                'most_accessed': None,
                'oldest_file': None,
                'cache_hits': 0
            }
        
        total_size = self.metadata['file_size'].sum()
        most_accessed = self.metadata.loc[self.metadata['access_count'].idxmax()]
        
        return {
            'total_files': len(self.metadata),
            'total_size_mb': total_size / (1024 * 1024),
            'most_accessed': f"{most_accessed['molecule']} ({most_accessed['access_count']}íšŒ)",
            'cache_hits': self.metadata['access_count'].sum()
        }

class OptimizedHitranAPI:
    def __init__(self):
        """ìµœì í™”ëœ HITRAN API ì´ˆê¸°í™”"""
        # ë°ì´í„° í´ë” ìƒì„±
        os.makedirs("cache/", exist_ok=True)
        os.makedirs("data/", exist_ok=True)
        
        # ìºì‹œ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.cache = HitranCache()
        
        # HITRAN ë¶„ì ID ë§¤í•‘
        self.molecule_ids = {
            "H2O": 1, "CO2": 2, "O3": 3, "N2O": 4, "CO": 5, "CH4": 6,
            "O2": 7, "NO": 8, "SO2": 9, "NO2": 10, "NH3": 11, "HNO3": 12
        }
    
    def download_molecule_data(self, molecule, wavelength_min, wavelength_max, use_cache=True):
        """ë¶„ì ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìºì‹± ì§€ì›)"""
        # ìºì‹œ í™•ì¸
        if use_cache and self.cache.is_cached(molecule, wavelength_min, wavelength_max):
            print(f"ğŸš€ {molecule} ìºì‹œì—ì„œ ë¡œë“œ ì¤‘...")
            data = self.cache.load_from_cache(molecule, wavelength_min, wavelength_max)
            if data is not None:
                print(f"âœ… {molecule} ìºì‹œ ë¡œë“œ ì™„ë£Œ! (ë¼ì¸ ìˆ˜: {len(data)})")
                return data
        
        # ìºì‹œì— ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ
        try:
            wavenumber_min = 1e7 / wavelength_max
            wavenumber_max = 1e7 / wavelength_min
            
            print(f"ğŸ“¥ {molecule} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            if molecule not in self.molecule_ids:
                print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ì: {molecule}")
                return None
            
            molecule_id = self.molecule_ids[molecule]
            hitran_query = hitran.Hitran()
            
            data = hitran_query.query_lines(
                molecule_number=molecule_id, 
                isotopologue_number=1,
                min_frequency=wavenumber_min * u.cm**-1,
                max_frequency=wavenumber_max * u.cm**-1
            )
            
            print(f"âœ… {molecule} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! (ë¼ì¸ ìˆ˜: {len(data)})")
            
            # ìºì‹œì— ì €ì¥
            if use_cache:
                if self.cache.save_to_cache(molecule, wavelength_min, wavelength_max, data):
                    print(f"ğŸ’¾ {molecule} ë°ì´í„° ìºì‹œì— ì €ì¥ë¨")
            
            return data
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def download_multiple_molecules(self, molecules_params, max_workers=4):
        """
        ì—¬ëŸ¬ ë¶„ì ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ
        
        Args:
            molecules_params: [(molecule, wl_min, wl_max), ...] ë¦¬ìŠ¤íŠ¸
            max_workers: ë™ì‹œ ì‹¤í–‰í•  ìµœëŒ€ ìŠ¤ë ˆë“œ ìˆ˜
        """
        results = {}
        
        print(f"ğŸ”„ {len(molecules_params)}ê°œ ë¶„ì ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (ìµœëŒ€ {max_workers} ìŠ¤ë ˆë“œ)")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ëª¨ë“  ë‹¤ìš´ë¡œë“œ ì‘ì—… ì œì¶œ
            future_to_molecule = {
                executor.submit(self.download_molecule_data, mol, wl_min, wl_max): mol
                for mol, wl_min, wl_max in molecules_params
            }
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future in concurrent.futures.as_completed(future_to_molecule):
                molecule = future_to_molecule[future]
                try:
                    data = future.result()
                    results[molecule] = data
                except Exception as e:
                    print(f"âŒ {molecule} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    results[molecule] = None
        
        print(f"âœ… ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! ì„±ê³µ: {sum(1 for v in results.values() if v is not None)}/{len(molecules_params)}")
        return results
    
    def get_cache_info(self):
        """ìºì‹œ ì •ë³´ ë°˜í™˜"""
        return self.cache.get_cache_stats()

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("=== ìµœì í™”ëœ HITRAN API í…ŒìŠ¤íŠ¸ (ë³‘ë ¬ ì²˜ë¦¬ í¬í•¨) ===")
    
    api = OptimizedHitranAPI()
    
    # === ê¸°ë³¸ ìºì‹œ í…ŒìŠ¤íŠ¸ ===
    print("\n1ï¸âƒ£ ìºì‹œ í…ŒìŠ¤íŠ¸")
    cache_stats = api.get_cache_info()
    print("ì´ˆê¸° ìºì‹œ í†µê³„:", cache_stats)
    
    data1 = api.download_molecule_data("H2O", 1500, 1520)
    
    # === ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===
    print("\n2ï¸âƒ£ ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    molecules = [
        ("H2O", 1500, 1520),   # ë¬¼ (ìºì‹œë¨)
        ("CH4", 1640, 1680),   # ë©”íƒ„ (ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ)
        ("CO2", 2000, 2020),   # ì´ì‚°í™”íƒ„ì†Œ (ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ)
    ]
    
    start_time = time.time()
    parallel_results = api.download_multiple_molecules(molecules, max_workers=3)
    parallel_time = time.time() - start_time
    
    print(f"\në³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì‹œê°„: {parallel_time:.2f}ì´ˆ")
    print("ë‹¤ìš´ë¡œë“œëœ ë¶„ì:", [mol for mol, data in parallel_results.items() if data is not None])
    
    # === ìµœì¢… ìºì‹œ í†µê³„ ===
    print("\n3ï¸âƒ£ ìµœì¢… ìºì‹œ í†µê³„")
    final_stats = api.get_cache_info()
    print("ìµœì¢… ìºì‹œ í†µê³„:", final_stats)
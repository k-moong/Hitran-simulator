"""
ìµœì í™”ëœ HITRAN API (ìºì‹± + ë³‘ë ¬ ì²˜ë¦¬ + ë©”ëª¨ë¦¬ ìµœì í™”)
"""

from astroquery import hitran
import os
import pandas as pd
import astropy.units as u
import concurrent.futures
import pickle
import gzip
import hashlib
from datetime import datetime
import time
import gc
import psutil
import numpy as np
from typing import List, Dict, Any, Optional

class MemoryMonitor:
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§"""
    
    @staticmethod
    def get_memory_usage():
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (MB)"""
        process = psutil.Process()
        memory_info = process.memory_info()
        return {
            'rss_mb': memory_info.rss / 1024 / 1024,  # ë¬¼ë¦¬ ë©”ëª¨ë¦¬
            'vms_mb': memory_info.vms / 1024 / 1024,  # ê°€ìƒ ë©”ëª¨ë¦¬
            'percent': process.memory_percent()        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ëŒ€ë¹„ %
        }
    
    @staticmethod
    def get_system_memory():
        """ì‹œìŠ¤í…œ ì „ì²´ ë©”ëª¨ë¦¬ ì •ë³´"""
        memory = psutil.virtual_memory()
        return {
            'total_gb': memory.total / 1024 / 1024 / 1024,
            'available_gb': memory.available / 1024 / 1024 / 1024,
            'used_percent': memory.percent
        }
    
    @staticmethod
    def print_memory_status(label=""):
        """ë©”ëª¨ë¦¬ ìƒíƒœ ì¶œë ¥"""
        process_mem = MemoryMonitor.get_memory_usage()
        system_mem = MemoryMonitor.get_system_memory()
        
        print(f"ğŸ§  ë©”ëª¨ë¦¬ ìƒíƒœ {label}:")
        print(f"   í”„ë¡œì„¸ìŠ¤: {process_mem['rss_mb']:.1f}MB ({process_mem['percent']:.1f}%)")
        print(f"   ì‹œìŠ¤í…œ: {system_mem['used_percent']:.1f}% ì‚¬ìš©ì¤‘ ({system_mem['available_gb']:.1f}GB ì‚¬ìš©ê°€ëŠ¥)")

class OptimizedHitranCache:
    """ë©”ëª¨ë¦¬ ìµœì í™”ëœ ìºì‹œ ì‹œìŠ¤í…œ"""
    
    def __init__(self, cache_dir="cache/hitran_cache", compression_level=6):
        self.cache_dir = cache_dir
        self.compression_level = compression_level
        
        # ìºì‹œ í´ë” ìƒì„±
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼
        self.metadata_file = os.path.join(cache_dir, "cache_metadata.json")
        self.load_metadata()
    
    def load_metadata(self):
        """ìºì‹œ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if os.path.exists(self.metadata_file):
            try:
                self.metadata = pd.read_json(self.metadata_file)
            except:
                self.metadata = pd.DataFrame(columns=['cache_key', 'file_path', 'created_time', 'access_count', 'file_size', 'compressed_size'])
        else:
            self.metadata = pd.DataFrame(columns=['cache_key', 'file_path', 'created_time', 'access_count', 'file_size', 'compressed_size'])
    
    def save_metadata(self):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        self.metadata.to_json(self.metadata_file, orient='records', date_format='iso')
    
    def generate_cache_key(self, molecule, wavelength_min, wavelength_max):
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_string = f"{molecule}_{wavelength_min}_{wavelength_max}"
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def get_cache_path(self, cache_key):
        """ì••ì¶•ëœ ìºì‹œ íŒŒì¼ ê²½ë¡œ"""
        return os.path.join(self.cache_dir, f"{cache_key}.pkl.gz")
    
    def is_cached(self, molecule, wavelength_min, wavelength_max):
        """ìºì‹œ ì¡´ì¬ í™•ì¸"""
        cache_key = self.generate_cache_key(molecule, wavelength_min, wavelength_max)
        cache_path = self.get_cache_path(cache_key)
        return os.path.exists(cache_path)
    
    def save_to_cache(self, molecule, wavelength_min, wavelength_max, data):
        """ì••ì¶•í•˜ì—¬ ìºì‹œì— ì €ì¥"""
        cache_key = self.generate_cache_key(molecule, wavelength_min, wavelength_max)
        cache_path = self.get_cache_path(cache_key)
        
        try:
            # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
            MemoryMonitor.print_memory_status("ìºì‹œ ì €ì¥ ì „")
            
            # ë°ì´í„° ì••ì¶• ì €ì¥
            with gzip.open(cache_path, 'wb', compresslevel=self.compression_level) as f:
                pickle.dump(data, f)
            
            # íŒŒì¼ í¬ê¸° ì •ë³´
            compressed_size = os.path.getsize(cache_path)
            
            # ì›ë³¸ í¬ê¸° ì¶”ì • (ì••ì¶• í•´ì œ ì—†ì´)
            original_size = len(pickle.dumps(data))
            compression_ratio = compressed_size / original_size if original_size > 0 else 0
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            new_entry = pd.DataFrame({
                'cache_key': [cache_key],
                'file_path': [cache_path],
                'created_time': [datetime.now().isoformat()],
                'access_count': [1],
                'file_size': [original_size],
                'compressed_size': [compressed_size],
                'molecule': [molecule],
                'wavelength_min': [wavelength_min],
                'wavelength_max': [wavelength_max],
                'compression_ratio': [compression_ratio]
            })
            
            # ê¸°ì¡´ í•­ëª© ì œê±° í›„ ì¶”ê°€
            self.metadata = self.metadata[self.metadata['cache_key'] != cache_key]
            self.metadata = pd.concat([self.metadata, new_entry], ignore_index=True)
            self.save_metadata()
            
            print(f"ğŸ’¾ ì••ì¶• ì €ì¥: {original_size/1024:.1f}KB â†’ {compressed_size/1024:.1f}KB ({compression_ratio*100:.1f}%)")
            
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            del data
            gc.collect()
            
            MemoryMonitor.print_memory_status("ìºì‹œ ì €ì¥ í›„")
            
            return True
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def load_from_cache(self, molecule, wavelength_min, wavelength_max):
        """ì••ì¶•ëœ ìºì‹œì—ì„œ ë¡œë“œ"""
        cache_key = self.generate_cache_key(molecule, wavelength_min, wavelength_max)
        cache_path = self.get_cache_path(cache_key)
        
        try:
            MemoryMonitor.print_memory_status("ìºì‹œ ë¡œë“œ ì „")
            
            # ì••ì¶• í•´ì œí•˜ì—¬ ë¡œë“œ
            with gzip.open(cache_path, 'rb') as f:
                data = pickle.load(f)
            
            # ì ‘ê·¼ íšŸìˆ˜ ì¦ê°€
            mask = self.metadata['cache_key'] == cache_key
            if mask.any():
                self.metadata.loc[mask, 'access_count'] += 1
                self.save_metadata()
            
            MemoryMonitor.print_memory_status("ìºì‹œ ë¡œë“œ í›„")
            
            return data
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_cache_stats(self):
        """ìºì‹œ í†µê³„ (ì••ì¶• ì •ë³´ í¬í•¨)"""
        if len(self.metadata) == 0:
            return {
                'total_files': 0,
                'total_size_mb': 0,
                'compressed_size_mb': 0,
                'compression_ratio': 0,
                'most_accessed': None,
                'cache_hits': 0
            }
        
        total_size = self.metadata['file_size'].sum() if 'file_size' in self.metadata.columns else 0
        compressed_size = self.metadata['compressed_size'].sum() if 'compressed_size' in self.metadata.columns else 0
        
        most_accessed = self.metadata.loc[self.metadata['access_count'].idxmax()]
        avg_compression = compressed_size / total_size if total_size > 0 else 0
        
        return {
            'total_files': len(self.metadata),
            'total_size_mb': total_size / (1024 * 1024),
            'compressed_size_mb': compressed_size / (1024 * 1024),
            'compression_ratio': avg_compression,
            'space_saved_mb': (total_size - compressed_size) / (1024 * 1024),
            'most_accessed': f"{most_accessed['molecule']} ({most_accessed['access_count']}íšŒ)",
            'cache_hits': self.metadata['access_count'].sum()
        }
    
    def cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        gc.collect()
        MemoryMonitor.print_memory_status("ë©”ëª¨ë¦¬ ì •ë¦¬ í›„")

class MemoryOptimizedHitranAPI:
    """ë©”ëª¨ë¦¬ ìµœì í™”ëœ HITRAN API"""
    
    def __init__(self, max_memory_mb=1000):
        """ì´ˆê¸°í™”"""
        self.max_memory_mb = max_memory_mb
        
        # í´ë” ìƒì„±
        os.makedirs("cache/", exist_ok=True)
        os.makedirs("data/", exist_ok=True)
        
        # ìµœì í™”ëœ ìºì‹œ ì‹œìŠ¤í…œ
        self.cache = OptimizedHitranCache()
        
        # ë¶„ì ID ë§¤í•‘
        self.molecule_ids = {
            "H2O": 1, "CO2": 2, "O3": 3, "N2O": 4, "CO": 5, "CH4": 6,
            "O2": 7, "NO": 8, "SO2": 9, "NO2": 10, "NH3": 11, "HNO3": 12
        }
        
        MemoryMonitor.print_memory_status("API ì´ˆê¸°í™”")
    
    def check_memory_limit(self):
        """ë©”ëª¨ë¦¬ í•œê³„ í™•ì¸"""
        memory_usage = MemoryMonitor.get_memory_usage()
        if memory_usage['rss_mb'] > self.max_memory_mb:
            print(f"âš ï¸ ë©”ëª¨ë¦¬ í•œê³„ ì´ˆê³¼: {memory_usage['rss_mb']:.1f}MB > {self.max_memory_mb}MB")
            print("ğŸ§¹ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰...")
            gc.collect()
            return False
        return True
    
    def download_molecule_data_chunked(self, molecule, wavelength_min, wavelength_max, chunk_size=100, use_cache=True):
        """ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„ì ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        
        # ìºì‹œ í™•ì¸
        if use_cache and self.cache.is_cached(molecule, wavelength_min, wavelength_max):
            print(f"ğŸš€ {molecule} ìºì‹œì—ì„œ ë¡œë“œ ì¤‘...")
            data = self.cache.load_from_cache(molecule, wavelength_min, wavelength_max)
            if data is not None:
                print(f"âœ… {molecule} ìºì‹œ ë¡œë“œ ì™„ë£Œ! (ë¼ì¸ ìˆ˜: {len(data)})")
                return data
        
        # ë©”ëª¨ë¦¬ í™•ì¸
        if not self.check_memory_limit():
            print("âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ ì¤‘ë‹¨")
            return None
        
        try:
            wavenumber_min = 1e7 / wavelength_max
            wavenumber_max = 1e7 / wavelength_min
            
            print(f"ğŸ“¥ {molecule} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ (ì²­í¬ í¬ê¸°: {chunk_size})")
            MemoryMonitor.print_memory_status("ë‹¤ìš´ë¡œë“œ ì‹œì‘")
            
            if molecule not in self.molecule_ids:
                print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ì: {molecule}")
                return None
            
            molecule_id = self.molecule_ids[molecule]
            hitran_query = hitran.Hitran()
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            data = hitran_query.query_lines(
                molecule_number=molecule_id, 
                isotopologue_number=1,
                min_frequency=wavenumber_min * u.cm**-1,
                max_frequency=wavenumber_max * u.cm**-1
            )
            
            print(f"âœ… {molecule} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! (ë¼ì¸ ìˆ˜: {len(data)})")
            MemoryMonitor.print_memory_status("ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            
            # ìºì‹œì— ì €ì¥
            if use_cache:
                self.cache.save_to_cache(molecule, wavelength_min, wavelength_max, data)
            
            return data
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
        finally:
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
    
    def download_multiple_molecules_optimized(self, molecules_params, max_workers=3):
        """ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ"""
        results = {}
        
        print(f"ğŸ”„ {len(molecules_params)}ê°œ ë¶„ì ë©”ëª¨ë¦¬ ìµœì í™” ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ")
        MemoryMonitor.print_memory_status("ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê³ ë ¤í•˜ì—¬ worker ìˆ˜ ì¡°ì •
        memory_info = MemoryMonitor.get_system_memory()
        if memory_info['available_gb'] < 2:  # 2GB ë¯¸ë§Œì´ë©´ worker ìˆ˜ ê°ì†Œ
            max_workers = min(max_workers, 2)
            print(f"âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ worker ìˆ˜ ì¡°ì •: {max_workers}")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_molecule = {
                executor.submit(self.download_molecule_data_chunked, mol, wl_min, wl_max): mol
                for mol, wl_min, wl_max in molecules_params
            }
            
            for future in concurrent.futures.as_completed(future_to_molecule):
                molecule = future_to_molecule[future]
                try:
                    data = future.result()
                    results[molecule] = data
                    
                    # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
                    if not self.check_memory_limit():
                        print(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ (ì²˜ë¦¬ ì™„ë£Œ: {molecule})")
                        
                except Exception as e:
                    print(f"âŒ {molecule} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    results[molecule] = None
        
        # ìµœì¢… ë©”ëª¨ë¦¬ ì •ë¦¬
        self.cache.cleanup_memory()
        
        print(f"âœ… ë©”ëª¨ë¦¬ ìµœì í™” ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! ì„±ê³µ: {sum(1 for v in results.values() if v is not None)}/{len(molecules_params)}")
        MemoryMonitor.print_memory_status("ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        
        return results
    
    def get_optimization_stats(self):
        """ìµœì í™” í†µê³„ ë°˜í™˜"""
        cache_stats = self.cache.get_cache_stats()
        memory_stats = MemoryMonitor.get_memory_usage()
        system_stats = MemoryMonitor.get_system_memory()
        
        return {
            'cache': cache_stats,
            'memory': memory_stats,
            'system': system_stats
        }

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("=== ë©”ëª¨ë¦¬ ìµœì í™”ëœ HITRAN API í…ŒìŠ¤íŠ¸ ===")
    
    # ì‹œìŠ¤í…œ ì •ë³´
    system_info = MemoryMonitor.get_system_memory()
    print(f"ğŸ’» ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬: {system_info['total_gb']:.1f}GB (ì‚¬ìš©ê°€ëŠ¥: {system_info['available_gb']:.1f}GB)")
    
    api = MemoryOptimizedHitranAPI(max_memory_mb=500)  # 500MB ì œí•œ
    
    # === ë©”ëª¨ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸ ===
    print("\n1ï¸âƒ£ ë‹¨ì¼ ë¶„ì í…ŒìŠ¤íŠ¸ (ë©”ëª¨ë¦¬ ìµœì í™”)")
    data1 = api.download_molecule_data_chunked("H2O", 1500, 1520)
    
    # === ë³‘ë ¬ + ë©”ëª¨ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸ ===
    print("\n2ï¸âƒ£ ë³‘ë ¬ + ë©”ëª¨ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸")
    molecules = [
        ("H2O", 1500, 1520),   # ìºì‹œë¨
        ("CH4", 1640, 1680),   # ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ
        ("CO2", 2000, 2020),   # ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ
        ("NH3", 1450, 1470),   # ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ
    ]
    
    start_time = time.time()
    results = api.download_multiple_molecules_optimized(molecules, max_workers=3)
    total_time = time.time() - start_time
    
    print(f"\nâš¡ ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {[mol for mol, data in results.items() if data is not None]}")
    
    # === ìµœì í™” í†µê³„ ===
    print("\n3ï¸âƒ£ ìµœì í™” í†µê³„")
    stats = api.get_optimization_stats()
    
    print("ğŸ“Š ìºì‹œ í†µê³„:")
    cache = stats['cache']
    print(f"   íŒŒì¼ ìˆ˜: {cache['total_files']}ê°œ")
    print(f"   ì›ë³¸ í¬ê¸°: {cache['total_size_mb']:.2f}MB")
    print(f"   ì••ì¶• í¬ê¸°: {cache['compressed_size_mb']:.2f}MB")
    print(f"   ì••ì¶•ë¥ : {cache['compression_ratio']*100:.1f}%")
    print(f"   ì ˆì•½ ê³µê°„: {cache['space_saved_mb']:.2f}MB")
    
    print("ğŸ§  ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ:")
    memory = stats['memory']
    print(f"   í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬: {memory['rss_mb']:.1f}MB")
    print(f"   ì‹œìŠ¤í…œ ì‚¬ìš©ë¥ : {stats['system']['used_percent']:.1f}%")